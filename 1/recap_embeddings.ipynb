{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ypt7ymI8X-rM"
   },
   "source": [
    "<h1><center>Векторные представления слов</center></h1>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z3sSyfHaX-rN"
   },
   "source": [
    "![w2v](https://cdn-images-1.medium.com/max/2600/1*sXNXYfAqfLUeiDXPCo130w.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0oH_UDyFX-rO"
   },
   "source": [
    "Есть три сценария работы с векторными представлениями:\n",
    "- Взять предобученную модель\n",
    "- Обучить свою модель \n",
    "- Взять предобученную модель и дообучить ее\n",
    "\n",
    "\n",
    "## Предобученные модели: RusVectōrēs\n",
    "\n",
    "\n",
    "На сайте [RusVectōrēs](https://rusvectores.org/ru/) собраны предобученные на различных данных модели для русского языка, а также можно поискать наиболее близкие слова к заданному, посчитать семантическую близость нескольких слов и порешать примеры с помощью «калькулятора семантической близости».\n",
    "\n",
    "\n",
    "Для других языков также можно найти предобученные модели — например, модели [fastText](https://fasttext.cc/docs/en/english-vectors.html) и [GloVe](https://nlp.stanford.edu/projects/glove/) (о них чуть дальше)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yXNm8flVX-rP"
   },
   "source": [
    "## Gensim\n",
    "\n",
    "Использовать предобученную модель или обучить свою можно с помощью библиотеки `gensim`. Вот [ее документация](https://radimrehurek.com/gensim/models/word2vec.html).\n",
    "\n",
    "### Как использовать готовую модель\n",
    "\n",
    "Модели word2vec бывают разных форматов:\n",
    "\n",
    "* .vec.gz — обычный текстовый файл \n",
    "* .bin.gz — бинарный файл\n",
    "\n",
    "Загружаются они с помощью одного и того же класса `KeyedVectors`, меняется только параметр `binary` у функции `load_word2vec_format`. \n",
    "\n",
    "Если же векторы обучены **не** с помощью word2vec, то для загрузки нужно использовать функцию `load`. Т.е. для загрузки предобученных моделей *glove, fasttext, bpe* и любых других нужна именно она.\n",
    "\n",
    "Скачаем с RusVectōrēs модель для русского языка, обученную на НКРЯ : https://rusvectores.org/ru/models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "sTLnNKaNX-rP",
    "outputId": "73be423c-b644-4fb2-860c-337c966cf788"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/veronica/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import gensim\n",
    "import logging\n",
    "import nltk.data \n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import word2vec\n",
    "from nltk.tokenize import sent_tokenize, RegexpTokenizer\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  608M  100  608M    0     0  9552k      0  0:01:05  0:01:05 --:--:-- 9865k      0  0:01:08  0:00:36  0:00:32  9.8M0:01:07  0:00:41  0:00:26 9973k:06  0:00:46  0:00:20 10.0M:01:05  0:01:01  0:00:04 10.0M\n"
     ]
    }
   ],
   "source": [
    "#!curl http://vectors.nlpl.eu/repository/20/220.zip -o ru_embeddings.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!unzip ru_embeddings.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alice.txt                 regular_expressions.ipynb test_data.csv\r\n",
      "classification.ipynb      ru_analogy_tagged.txt     test_labels.csv\r\n",
      "\u001b[34mdata\u001b[m\u001b[m                      \u001b[34mru_embeddings\u001b[m\u001b[m             text_preprocessing.ipynb\r\n",
      "pipeline.png              ru_embeddings.zip         train_data.csv\r\n",
      "recap_embeddings.ipynb    ruscorpora_mystem_cbow\r\n"
     ]
    }
   ],
   "source": [
    "!ls ru_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "mkuCawyFX-rW",
    "outputId": "ea312dc3-ebfa-4ac1-b4cb-7b96c6d4ab7e"
   },
   "outputs": [],
   "source": [
    "model_path = 'ru_embeddings/model.bin'\n",
    "\n",
    "model_ru = gensim.models.KeyedVectors.load_word2vec_format(model_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H4D0hMgkX-rY"
   },
   "outputs": [],
   "source": [
    "words = ['день_NOUN', 'ночь_NOUN', 'человек_NOUN', 'семантика_NOUN', 'биткоин_NOUN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jbTShU9aX-ra"
   },
   "source": [
    "Частеречные тэги нужны, поскольку это специфика скачанной модели - она была натренирована на словах, аннотированных их частями речи (и лемматизированных). **Важно!** В названиях моделей на `rusvectores` указано, какой набор тегов они используют (mystem, upos и т.д.)\n",
    "\n",
    "Попросим у модели 10 ближайших соседей для каждого слова и коэффициент косинусной близости для каждого:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "9Uer5sHyX-ra",
    "outputId": "b5eec20b-995c-42e7-855c-388ded24682c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "день_NOUN\n",
      "неделя_NOUN :  0.767143726348877\n",
      "месяц_NOUN :  0.7355298399925232\n",
      "утро_NOUN :  0.6559638381004333\n",
      "час_NOUN :  0.632419228553772\n",
      "ночь_NOUN :  0.5809687972068787\n",
      "сутки_NOUN :  0.5776056051254272\n",
      "вечер_NOUN :  0.5675091743469238\n",
      "минута_NOUN :  0.5483242869377136\n",
      "день»_PROPN :  0.5270609259605408\n",
      "денька_NOUN :  0.5157712697982788\n",
      "\n",
      "\n",
      "ночь_NOUN\n",
      "вечер_NOUN :  0.7615348100662231\n",
      "утро_NOUN :  0.7531793713569641\n",
      "рассвет_NOUN :  0.727114737033844\n",
      "полночь_NOUN :  0.6713059544563293\n",
      "полдень_NOUN :  0.6476588845252991\n",
      "сумерки_NOUN :  0.6017960906028748\n",
      "утр_NOUN :  0.5851606130599976\n",
      "день_NOUN :  0.5809689164161682\n",
      "темнота_NOUN :  0.5586054921150208\n",
      "ночной_ADJ :  0.5421528220176697\n",
      "\n",
      "\n",
      "человек_NOUN\n",
      "житель_NOUN :  0.6111521124839783\n",
      "женщина_NOUN :  0.5880182385444641\n",
      "мужчина_NOUN :  0.5467938780784607\n",
      "душа_NOUN :  0.5095201134681702\n",
      "более_ADV :  0.4962872266769409\n",
      "население_NOUN :  0.476238489151001\n",
      "человеческий_ADJ :  0.4728814661502838\n",
      "солдат_NOUN :  0.4657357931137085\n",
      "пациент_NOUN :  0.4500826597213745\n",
      "ребенок_NOUN :  0.4453369379043579\n",
      "\n",
      "\n",
      "семантика_NOUN\n",
      "семантический_ADJ :  0.7910399436950684\n",
      "синтаксический_ADJ :  0.7384093403816223\n",
      "синтаксис_NOUN :  0.711597740650177\n",
      "семантика_PROPN :  0.6700522899627686\n",
      "референция_NOUN :  0.6674174666404724\n",
      "лингвистический_ADJ :  0.6506385803222656\n",
      "грамматический_ADJ :  0.6489706039428711\n",
      "диахронический_ADJ :  0.6474006772041321\n",
      "предикативный_ADJ :  0.6456335186958313\n",
      "смысловой_ADJ :  0.6449253559112549\n",
      "\n",
      "\n",
      "Увы, слова \"биткоин_NOUN\" нет в модели!\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    # есть ли слово в модели? \n",
    "    if word in model_ru:\n",
    "        print(word)\n",
    "        # выдаем 10 ближайших соседей слова:\n",
    "        for word, sim in model_ru.most_similar(positive=[word], topn=10):\n",
    "            # слово + коэффициент косинусной близости\n",
    "            print(word, ': ', sim)\n",
    "        print('\\n')\n",
    "    else:\n",
    "        # Увы!\n",
    "        print(f'Увы, слова \"{word}\" нет в модели!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key 'биткоин_NOUN' not present\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sz/c3kzvnt14rlgyfdclllygz9w0000gn/T/ipykernel_56164/4084379448.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_ru\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'биткоин_NOUN'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key_or_keys)\u001b[0m\n\u001b[1;32m    402\u001b[0m         \"\"\"\n\u001b[1;32m    403\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_or_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_KEY_TYPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_or_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkey_or_keys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, key, norm)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \"\"\"\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_norms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_index\u001b[0;34m(self, key, default)\u001b[0m\n\u001b[1;32m    419\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Key '{key}' not present\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Key 'биткоин_NOUN' not present\""
     ]
    }
   ],
   "source": [
    "model_ru['биткоин_NOUN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1GqDmAcJX-rc"
   },
   "source": [
    "Находим косинусную близость пары слов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "MDFjOSJjX-rd",
    "outputId": "b58343ff-8063-4cca-8cbb-371cbf4717ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26860568\n"
     ]
    }
   ],
   "source": [
    "print(model_ru.similarity('человек_NOUN', 'обезьяна_NOUN'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B0w4pQooX-rf"
   },
   "source": [
    "Построим аналогии: \n",
    "* *король: мужчина = королева: женщина* \n",
    " $\\Rightarrow$ \n",
    "* *король - мужчина + женщина = королева*\n",
    "\n",
    "\n",
    "Что получится, если вычесть из пиццы Италию и прибавить Россию?\n",
    "\n",
    "* positive — вектора, которые мы складываем\n",
    "* negative — вектора, которые вычитаем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "N0L5_TCQX-rf",
    "outputId": "18c0c545-9843-4325-82bb-a3614e0ac023"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "хот-дог_NOUN\n"
     ]
    }
   ],
   "source": [
    "print(model_ru.most_similar(positive=['пицца_NOUN', 'россия_NOUN'], negative=['италия_NOUN'])[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "DrN2Jc31X-rh",
    "outputId": "55ec81c1-8fa2-4998-e094-bca1a2aae04d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ананас_NOUN'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ru.doesnt_match('пицца_NOUN пельмень_NOUN хот-дог_NOUN ананас_NOUN'.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобученные модели: GloVe\n",
    "\n",
    "Скачаем модель с сайта: https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! wget https://nlp.stanford.edu/data/glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  glove.6B.zip\n",
      "  inflating: glove.6B.50d.txt        \n",
      "  inflating: glove.6B.100d.txt       \n",
      "  inflating: glove.6B.200d.txt       \n",
      "  inflating: glove.6B.300d.txt       \n"
     ]
    }
   ],
   "source": [
    "!unzip glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the -0.038194 -0.24487 0.72812 -0.39961 0.083172 0.043953 -0.39141 0.3344 -0.57545 0.087459 0.28787 -0.06731 0.30906 -0.26384 -0.13231 -0.20757 0.33395 -0.33848 -0.31743 -0.48336 0.1464 -0.37304 0.34577 0.052041 0.44946 -0.46971 0.02628 -0.54155 -0.15518 -0.14107 -0.039722 0.28277 0.14393 0.23464 -0.31021 0.086173 0.20397 0.52624 0.17164 -0.082378 -0.71787 -0.41531 0.20335 -0.12763 0.41367 0.55187 0.57908 -0.33477 -0.36559 -0.54857 -0.062892 0.26584 0.30205 0.99775 -0.80481 -3.0243 0.01254 -0.36942 2.2167 0.72201 -0.24978 0.92136 0.034514 0.46745 1.1079 -0.19358 -0.074575 0.23353 -0.052062 -0.22044 0.057162 -0.15806 -0.30798 -0.41625 0.37972 0.15006 -0.53212 -0.2055 -1.2526 0.071624 0.70565 0.49744 -0.42063 0.26148 -1.538 -0.30223 -0.073438 -0.28312 0.37104 -0.25217 0.016215 -0.017099 -0.38984 0.87424 -0.72569 -0.51058 -0.52028 -0.1459 0.8278 0.27062\r\n"
     ]
    }
   ],
   "source": [
    "! head -n 1 glove.6B.100d.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "glove = {}\n",
    "with open('./glove.6B/glove.6B.200d.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        word, embedding = line.split(' ',1)\n",
    "        wordEmbedding = np.array([float(value) for value in embedding[1:].split(' ')])\n",
    "        glove[word] = wordEmbedding\n",
    "\n",
    "print(len(glove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glove['hello'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобученные модели: fastText\n",
    "\n",
    "FastText использует не только векторы слов, но и векторы n-грам. В корпусе каждое слово автоматически представляется в виде набора символьных n-грамм. Скажем, если мы установим n=3, то вектор для слова \"where\" будет представлен суммой векторов следующих триграм: \"<wh\", \"whe\", \"her\", \"ere\", \"re>\" (где \"<\" и \">\" символы, обозначающие начало и конец слова). Благодаря этому мы можем также получать вектора для слов, отсутствуюших в словаре, а также эффективно работать с текстами, содержащими ошибки и опечатки.\n",
    "\n",
    "* [Статья](https://aclweb.org/anthology/Q17-1010)\n",
    "* [Сайт](https://fasttext.cc/)\n",
    "* [Руководство](https://fasttext.cc/docs/en/support.html)\n",
    "* [Репозиторий](https://github.com/facebookresearch/fasttext)\n",
    "\n",
    "Есть библиотека `fasttext` для питона (с готовыми моделями можно работать и через `gensim`).\n",
    "\n",
    "На сайте проекта можно найти предобученные модели для 157 языков (в том числе русского): https://fasttext.cc/docs/en/crawl-vectors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = fasttext.load_model('cc.ru.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.90226841e-02,  2.94893887e-02,  7.75389597e-02,  5.80755584e-02,\n",
       "       -2.04796474e-02, -2.60778125e-02, -4.31554951e-02, -7.66336499e-03,\n",
       "        7.35045224e-03,  8.39629862e-03, -3.03267990e-03,  6.59276769e-02,\n",
       "        2.52222875e-03, -1.30695077e-02,  4.03538942e-02,  1.97116341e-02,\n",
       "        7.49906823e-02,  3.26768160e-02, -1.30058741e-02,  5.22828884e-02,\n",
       "        5.06116338e-02, -7.52337575e-02, -3.59434858e-02,  4.87469845e-02,\n",
       "        1.21515250e-05,  2.44456176e-02, -6.05776981e-02,  3.70115340e-02,\n",
       "        3.57847698e-02, -1.98335946e-02,  5.92223294e-02, -6.81746677e-02,\n",
       "       -1.24129206e-02, -3.59787606e-02, -4.27804003e-03,  4.76003997e-02,\n",
       "       -7.42428824e-02, -1.28765211e-01, -1.36825100e-01,  9.66134109e-03,\n",
       "       -5.21074906e-02,  1.38343694e-02, -2.73327827e-02,  5.51195256e-02,\n",
       "        2.06264984e-02,  5.95376752e-02,  2.22954024e-02,  7.45679426e-04,\n",
       "       -5.00567667e-02,  4.27671038e-02, -2.68213451e-02,  1.15477806e-02,\n",
       "       -2.37321910e-02,  3.29448245e-02, -3.59060019e-02, -6.77625239e-02,\n",
       "        1.04473326e-02,  1.50889102e-02, -2.78114676e-02, -9.76028666e-02,\n",
       "       -3.43934074e-02, -1.04172770e-02, -3.95480804e-02,  8.23004544e-03,\n",
       "        4.43044715e-02, -5.16277030e-02, -1.58495817e-03,  1.30589223e-02,\n",
       "        2.92139989e-03,  8.11357237e-03,  2.42509153e-02,  1.58560872e-02,\n",
       "        1.11486539e-02,  3.76834609e-02,  1.30302114e-02, -3.58502977e-02,\n",
       "        3.56120542e-02, -5.51831089e-02, -2.32887710e-03,  4.76860767e-03,\n",
       "       -4.78371978e-03,  2.99577117e-02, -3.09092756e-02, -6.36521801e-02,\n",
       "        2.03362219e-02,  2.66498933e-03, -8.36646780e-02, -7.17537245e-03,\n",
       "        8.98520052e-02,  6.66208640e-02, -8.96188617e-02,  5.34536690e-03,\n",
       "       -9.03579406e-03,  8.92835259e-02,  2.78102700e-02, -1.20203774e-02,\n",
       "       -2.41292827e-03, -1.15023619e-02, -3.44534665e-02, -2.43556350e-02,\n",
       "       -7.05607096e-03, -4.11733650e-02,  1.92692038e-02,  1.19909272e-03,\n",
       "       -1.21868670e-03, -5.36188670e-02,  5.19845784e-02,  2.51053344e-03,\n",
       "       -6.82635009e-02,  1.17374798e-02, -9.05148908e-02,  4.99660224e-02,\n",
       "        1.12783313e-01,  1.24725781e-03, -2.74479073e-02, -8.96990314e-05,\n",
       "        6.92080036e-02,  1.45684648e-03, -2.41988879e-02, -3.05815246e-02,\n",
       "        5.17066428e-03,  7.69108161e-03, -5.95876239e-02, -3.95577922e-02,\n",
       "       -5.22434339e-03,  3.09095122e-02, -2.98223142e-02, -7.57112056e-02,\n",
       "        4.94429357e-02,  5.03483489e-02,  4.14576894e-03, -3.37062441e-02,\n",
       "       -3.80479768e-02, -3.73744667e-02,  7.57561484e-03,  2.64757015e-02,\n",
       "        3.25574283e-03,  2.18765642e-02,  4.24088500e-02, -3.50630693e-02,\n",
       "        5.54031208e-02, -8.53787642e-03,  1.19881807e-02, -1.30064994e-01,\n",
       "       -5.70928156e-02, -7.49739036e-02, -4.37675416e-02, -2.35290714e-02,\n",
       "        4.50193062e-02, -9.09404084e-03, -4.47827242e-02, -1.77210849e-02,\n",
       "       -1.05877578e-01, -2.54368186e-02, -1.35848140e-02,  1.31518561e-02,\n",
       "        9.84252430e-03,  1.03610352e-01,  8.95494297e-02,  8.20680708e-03,\n",
       "        5.17309010e-02,  3.53422575e-02,  2.93518547e-02, -2.68315640e-03,\n",
       "        2.45563984e-02, -1.37855113e-02, -8.25848505e-02, -2.55577751e-02,\n",
       "        6.90167472e-02, -1.15719941e-02, -5.48847876e-02, -1.04961231e-01,\n",
       "       -2.70559490e-02, -3.56582142e-02, -5.01041189e-02, -2.91199442e-02,\n",
       "       -2.19394565e-02, -6.56976998e-02, -3.12608741e-02, -3.23637240e-02,\n",
       "       -7.50813708e-02,  8.37855563e-02,  4.47793305e-02, -2.74285376e-02,\n",
       "        4.54183817e-02, -2.78103482e-02,  6.49284497e-02, -2.38500033e-02,\n",
       "       -6.63511455e-03,  9.03142020e-02,  4.88595525e-03,  5.21496907e-02,\n",
       "       -5.44826463e-02, -1.13993289e-03,  8.48236308e-02, -5.48246168e-02,\n",
       "        1.53390333e-01, -5.71697950e-04,  1.42700663e-02, -1.30275860e-02,\n",
       "        8.65012687e-03,  1.22714564e-02,  1.69300865e-02,  2.29607075e-02,\n",
       "       -7.44452775e-02,  1.51818572e-02,  7.68800527e-02, -6.26277253e-02,\n",
       "        1.95666961e-02, -5.96546941e-02,  2.62541715e-02,  2.89816558e-02,\n",
       "        5.54927848e-02,  1.97875500e-02,  1.77371211e-03,  7.34284669e-02,\n",
       "        4.84075435e-02,  8.13406426e-03, -3.19512337e-02, -3.59821431e-02,\n",
       "        2.43038242e-03, -2.33888905e-02, -7.13486224e-02,  3.22470479e-02,\n",
       "        6.24932116e-03,  3.05196736e-02, -7.63035566e-02,  2.74270605e-02,\n",
       "       -2.94636339e-02,  7.15403408e-02,  4.15845476e-02,  5.25651593e-03,\n",
       "       -7.12789819e-02,  1.43155335e-02, -8.60781893e-02,  5.22206712e-04,\n",
       "       -6.64970353e-02, -1.76892467e-02, -1.44125810e-02, -1.12688266e-01,\n",
       "       -7.95892905e-03,  2.14078669e-02,  2.14393754e-02,  5.67282131e-03,\n",
       "        3.80397029e-02,  4.51862812e-02, -5.92934974e-02,  2.56342590e-02,\n",
       "       -1.34147201e-02, -2.59316415e-02,  7.45109171e-02,  3.16312276e-02,\n",
       "       -1.19421585e-02,  1.85775813e-02,  1.57254320e-02,  1.73833873e-02,\n",
       "       -6.95936903e-02, -4.40367265e-03, -3.95593718e-02, -1.94147956e-02,\n",
       "        4.49333750e-02, -1.81070566e-02, -5.35898767e-02,  4.37325016e-02,\n",
       "        6.83941832e-03, -3.00847143e-02, -1.11508211e-02,  4.33934405e-02,\n",
       "       -1.91740710e-02,  7.54076838e-02, -4.10673320e-02,  5.50695919e-02,\n",
       "        5.69503196e-02, -3.72967497e-02,  9.86716524e-03, -2.55110618e-02,\n",
       "       -2.46207975e-02, -2.20296606e-02, -2.08327528e-02,  9.03372467e-03,\n",
       "       -8.93854573e-02, -1.17132045e-01, -2.37822570e-02,  2.06042416e-02,\n",
       "       -4.70974110e-02,  4.29784134e-03,  2.73348554e-03, -3.65018807e-02,\n",
       "       -5.95521331e-02, -2.10720743e-03,  8.33550282e-03, -6.47981092e-02,\n",
       "        7.08063394e-02, -2.68884492e-03, -4.61591482e-02,  2.17411760e-02,\n",
       "       -7.07311854e-02,  6.36055395e-02,  1.93226598e-02,  1.78099480e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft['модель']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У fasttext есть все те же методы, что в gensim, но называются они иначе:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.764227032661438, 'кофе'),\n",
       " (0.739784836769104, 'Чай'),\n",
       " (0.7071998119354248, 'чая'),\n",
       " (0.7018463015556335, 'чаи'),\n",
       " (0.6877091526985168, 'свежезаваренный'),\n",
       " (0.6864805221557617, 'напиток'),\n",
       " (0.6854358911514282, 'каркадэ'),\n",
       " (0.6772830486297607, 'чай.'),\n",
       " (0.667264461517334, 'чай-'),\n",
       " (0.6647352576255798, 'чаёк')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.get_nearest_neighbors('чай')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.8757159113883972, 'актриса'),\n",
       " (0.7068515419960022, 'артистка'),\n",
       " (0.694389820098877, 'киноактриса'),\n",
       " (0.6874823570251465, 'Актриса'),\n",
       " (0.6860095262527466, 'кинозвезда'),\n",
       " (0.6789741516113281, 'певица'),\n",
       " (0.6663230061531067, 'красавица-актриса'),\n",
       " (0.6603893637657166, 'актриса.'),\n",
       " (0.6569409966468811, 'Киноактриса'),\n",
       " (0.6488985419273376, 'актрисса')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.get_analogies(\"женщина\", \"мужчина\", \"актер\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важная особенность: так как модель обучена на символьных n-граммах, нет проблемы OOV (out of vocabulary) слов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.7441761493682861, 'книженция'),\n",
       " (0.7169104218482971, 'книжица'),\n",
       " (0.6966618895530701, 'брошюрка'),\n",
       " (0.6812918782234192, 'книжонку'),\n",
       " (0.6812120079994202, 'книжонок'),\n",
       " (0.6565592288970947, 'книжонки'),\n",
       " (0.6502901911735535, 'книжонке'),\n",
       " (0.6479876637458801, 'книжечка'),\n",
       " (0.6242943406105042, 'статейка'),\n",
       " (0.6214005351066589, 'книга-то')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.get_nearest_neighbors('книжонка')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.7335842251777649, 'компъютер'),\n",
       " (0.7109572291374207, 'компютера'),\n",
       " (0.7098245024681091, 'компьютер'),\n",
       " (0.6971184015274048, 'компютерный'),\n",
       " (0.6874867081642151, 'копьютер'),\n",
       " (0.674636960029602, 'копм'),\n",
       " (0.6739663481712341, 'Компютер'),\n",
       " (0.6691707968711853, 'компутер'),\n",
       " (0.6670798063278198, 'компютеру'),\n",
       " (0.6656312346458435, 'комп')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.get_nearest_neighbors('компютер')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZNHMtmbqX-rl"
   },
   "source": [
    "## Как обучить свою модель: word2vec\n",
    "\n",
    "В качестве обучающих данных возьмем англоязычные отзывы о фильмах с сайта IMDB (данные взяты отсюда http://ai.stanford.edu/~amaas/data/sentiment/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4715_9.txt',\n",
       " '12390_8.txt',\n",
       " '8329_7.txt',\n",
       " '9063_8.txt',\n",
       " '3092_10.txt',\n",
       " '9865_8.txt',\n",
       " '6639_10.txt',\n",
       " '10460_10.txt',\n",
       " '10331_10.txt',\n",
       " '11606_10.txt']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.listdir('aclImdb/train/pos/')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12500"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = [f for f in os.listdir('aclImdb/train/pos/') if f.endswith('.txt')]\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12500"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = []\n",
    "\n",
    "for file in files:\n",
    "    with open (f'aclImdb/train/pos/{file}', 'r') as text_file:\n",
    "        text = text_file.read()\n",
    "        texts.append(text)\n",
    "        \n",
    "data = pd.DataFrame.from_dict({'review': texts})\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "eEGmrh-nX-rq",
    "outputId": "46b6d027-0919-48b6-9b92-9ce895d572d6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>For a movie that gets no respect there sure are a lot of memorable quotes listed for this gem. Imagine a movie where Joe Piscopo is actually funny! Maureen Stapleton is a scene stealer. The Moroni character is an absolute scream. Watch for Alan \"The Skipper\" Hale jr. as a police Sgt.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bizarre horror movie filled with famous faces but stolen by Cristina Raines (later of TV's \"Flamingo Road\") as a pretty but somewhat unstable model with a gummy smile who is slated to pay for her attempted suicides by guarding the Gateway to Hell! The scenes with Raines modeling are very well captured, the mood music is perfect, Deborah Raffin is charming as Cristina's pal, but when Raines moves into a creepy Brooklyn Heights brownstone (inhabited by a blind priest on the top floor), things really start cooking. The neighbors, including a fantastically wicked Burgess Meredith and kinky couple Sylvia Miles &amp; Beverly D'Angelo, are a diabolical lot, and Eli Wallach is great fun as a wily police detective. The movie is nearly a cross-pollination of \"Rosemary's Baby\" and \"The Exorcist\"--but...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A solid, if unremarkable film. Matthau, as Einstein, was wonderful. My favorite part, and the only thing that would make me go out of my way to see this again, was the wonderful scene with the physicists playing badmitton, I loved the sweaters and the conversation while they waited for Robbins to retrieve the birdie.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It's a strange feeling to sit alone in a theater occupied by parents and their rollicking kids. I felt like instead of a movie ticket, I should have been given a NAMBLA membership.&lt;br /&gt;&lt;br /&gt;Based upon Thomas Rockwell's respected Book, How To Eat Fried Worms starts like any children's story: moving to a new town. The new kid, fifth grader Billy Forrester was once popular, but has to start anew. Making friends is never easy, especially when the only prospect is Poindexter Adam. Or Erica, who at 4 1/2 feet, is a giant.&lt;br /&gt;&lt;br /&gt;Further complicating things is Joe the bully. His freckled face and sleeveless shirts are daunting. He antagonizes kids with the Death Ring: a Crackerjack ring that is rumored to kill you if you're punched with it. But not immediately. No, the death ring unleas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You probably all already know this by now, but 5 additional episodes never aired can be viewed on ABC.com I've watched a lot of television over the years and this is possibly my favorite show, ever. It's a crime that this beautifully written and acted show was canceled. The actors that played Laura, Whit, Carlos, Mae, Damian, Anya and omg, Steven Caseman - are all incredible and so natural in those roles. Even the kids are great. Wonderful show. So sad that it's gone. Of course I wonder about the reasons it was canceled. There is no way I'll let myself believe that Ms. Moynahan's pregnancy had anything to do with it. It was in the perfect time slot in this market. I've watched all the episodes again on ABC.com - I hope they all come out on DVD some day. Thanks for reading.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            review\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     For a movie that gets no respect there sure are a lot of memorable quotes listed for this gem. Imagine a movie where Joe Piscopo is actually funny! Maureen Stapleton is a scene stealer. The Moroni character is an absolute scream. Watch for Alan \"The Skipper\" Hale jr. as a police Sgt.\n",
       "1  Bizarre horror movie filled with famous faces but stolen by Cristina Raines (later of TV's \"Flamingo Road\") as a pretty but somewhat unstable model with a gummy smile who is slated to pay for her attempted suicides by guarding the Gateway to Hell! The scenes with Raines modeling are very well captured, the mood music is perfect, Deborah Raffin is charming as Cristina's pal, but when Raines moves into a creepy Brooklyn Heights brownstone (inhabited by a blind priest on the top floor), things really start cooking. The neighbors, including a fantastically wicked Burgess Meredith and kinky couple Sylvia Miles & Beverly D'Angelo, are a diabolical lot, and Eli Wallach is great fun as a wily police detective. The movie is nearly a cross-pollination of \"Rosemary's Baby\" and \"The Exorcist\"--but...\n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   A solid, if unremarkable film. Matthau, as Einstein, was wonderful. My favorite part, and the only thing that would make me go out of my way to see this again, was the wonderful scene with the physicists playing badmitton, I loved the sweaters and the conversation while they waited for Robbins to retrieve the birdie.\n",
       "3  It's a strange feeling to sit alone in a theater occupied by parents and their rollicking kids. I felt like instead of a movie ticket, I should have been given a NAMBLA membership.<br /><br />Based upon Thomas Rockwell's respected Book, How To Eat Fried Worms starts like any children's story: moving to a new town. The new kid, fifth grader Billy Forrester was once popular, but has to start anew. Making friends is never easy, especially when the only prospect is Poindexter Adam. Or Erica, who at 4 1/2 feet, is a giant.<br /><br />Further complicating things is Joe the bully. His freckled face and sleeveless shirts are daunting. He antagonizes kids with the Death Ring: a Crackerjack ring that is rumored to kill you if you're punched with it. But not immediately. No, the death ring unleas...\n",
       "4                  You probably all already know this by now, but 5 additional episodes never aired can be viewed on ABC.com I've watched a lot of television over the years and this is possibly my favorite show, ever. It's a crime that this beautifully written and acted show was canceled. The actors that played Laura, Whit, Carlos, Mae, Damian, Anya and omg, Steven Caseman - are all incredible and so natural in those roles. Even the kids are great. Wonderful show. So sad that it's gone. Of course I wonder about the reasons it was canceled. There is no way I'll let myself believe that Ms. Moynahan's pregnancy had anything to do with it. It was in the perfect time slot in this market. I've watched all the episodes again on ABC.com - I hope they all come out on DVD some day. Thanks for reading."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oIZaQ3kYX-rt"
   },
   "source": [
    "Убираем из данных ссылки, html-разметку и небуквенные символы, а затем приведем все к нижнему регистру и токенизируем. На выходе получается массив из предложений, каждое из которых представляет собой массив слов. Здесь используется токенизатор из библиотеки `nltk`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from tqdm.notebook import tqdm\n",
    "from multiprocessing import Pool\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "irbunSOfX-rt"
   },
   "outputs": [],
   "source": [
    "def review_to_wordlist(review, remove_stopwords=False ):\n",
    "    # убираем ссылки вне тегов\n",
    "    review = re.sub(r\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\", \" \", review)\n",
    "    review_text = BeautifulSoup(review, \"lxml\").get_text()\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "    words = review_text.lower().split()\n",
    "    if remove_stopwords:\n",
    "        stops = stopwords.words(\"english\")\n",
    "        words = [w for w in words if not w in stops]\n",
    "    return(words)\n",
    "\n",
    "def review_to_sentences(review, tokenizer=tokenizer, remove_stopwords=False):\n",
    "    raw_sentences = tokenizer.tokenize(review.strip())\n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        if len(raw_sentence) > 0:\n",
    "            sentences.append(review_to_wordlist(raw_sentence, remove_stopwords))\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500\n",
      "[['for', 'a', 'movie', 'that', 'gets', 'no', 'respect', 'there', 'sure', 'are', 'a', 'lot', 'of', 'memorable', 'quotes', 'listed', 'for', 'this', 'gem'], ['imagine', 'a', 'movie', 'where', 'joe', 'piscopo', 'is', 'actually', 'funny'], ['maureen', 'stapleton', 'is', 'a', 'scene', 'stealer'], ['the', 'moroni', 'character', 'is', 'an', 'absolute', 'scream'], ['watch', 'for', 'alan', 'the', 'skipper', 'hale', 'jr', 'as', 'a', 'police', 'sgt']] [['bizarre', 'horror', 'movie', 'filled', 'with', 'famous', 'faces', 'but', 'stolen', 'by', 'cristina', 'raines', 'later', 'of', 'tv', 's', 'flamingo', 'road', 'as', 'a', 'pretty', 'but', 'somewhat', 'unstable', 'model', 'with', 'a', 'gummy', 'smile', 'who', 'is', 'slated', 'to', 'pay', 'for', 'her', 'attempted', 'suicides', 'by', 'guarding', 'the', 'gateway', 'to', 'hell'], ['the', 'scenes', 'with', 'raines', 'modeling', 'are', 'very', 'well', 'captured', 'the', 'mood', 'music', 'is', 'perfect', 'deborah', 'raffin', 'is', 'charming', 'as', 'cristina', 's', 'pal', 'but', 'when', 'raines', 'moves', 'into', 'a', 'creepy', 'brooklyn', 'heights', 'brownstone', 'inhabited', 'by', 'a', 'blind', 'priest', 'on', 'the', 'top', 'floor', 'things', 'really', 'start', 'cooking'], ['the', 'neighbors', 'including', 'a', 'fantastically', 'wicked', 'burgess', 'meredith', 'and', 'kinky', 'couple', 'sylvia', 'miles', 'beverly', 'd', 'angelo', 'are', 'a', 'diabolical', 'lot', 'and', 'eli', 'wallach', 'is', 'great', 'fun', 'as', 'a', 'wily', 'police', 'detective'], ['the', 'movie', 'is', 'nearly', 'a', 'cross', 'pollination', 'of', 'rosemary', 's', 'baby', 'and', 'the', 'exorcist', 'but', 'what', 'a', 'combination'], ['based', 'on', 'the', 'best', 'seller', 'by', 'jeffrey', 'konvitz', 'the', 'sentinel', 'is', 'entertainingly', 'spooky', 'full', 'of', 'shocks', 'brought', 'off', 'well', 'by', 'director', 'michael', 'winner', 'who', 'mounts', 'a', 'thoughtfully', 'downbeat', 'ending', 'with', 'skill'], ['from']] [['a', 'solid', 'if', 'unremarkable', 'film'], ['matthau', 'as', 'einstein', 'was', 'wonderful'], ['my', 'favorite', 'part', 'and', 'the', 'only', 'thing', 'that', 'would', 'make', 'me', 'go', 'out', 'of', 'my', 'way', 'to', 'see', 'this', 'again', 'was', 'the', 'wonderful', 'scene', 'with', 'the', 'physicists', 'playing', 'badmitton', 'i', 'loved', 'the', 'sweaters', 'and', 'the', 'conversation', 'while', 'they', 'waited', 'for', 'robbins', 'to', 'retrieve', 'the', 'birdie']]\n"
     ]
    }
   ],
   "source": [
    "sentences = [review_to_sentences(review) for review in data[\"review\"].values]\n",
    "\n",
    "print(len(sentences))\n",
    "print(*sentences[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132111"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_sentences = [item for sublist in sentences for item in sublist]\n",
    "len(flat_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cqb_NOteX-rz"
   },
   "outputs": [],
   "source": [
    "# это понадобится нам позже для обучения модели fasttext\n",
    "\n",
    "with open('clean_text.txt', 'w') as f:\n",
    "    for s in flat_sentences:\n",
    "        f.write(' '.join(s))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qqFhuv7XX-r1"
   },
   "source": [
    "Обучаем и сохраняем модель. \n",
    "\n",
    "\n",
    "Основные параметры:\n",
    "* данные должны быть итерируемым объектом \n",
    "* vector_size — размер вектора, \n",
    "* window — размер окна наблюдения,\n",
    "* min_count — мин. частотность слова в корпусе,\n",
    "* sg — используемый алгоритм обучения (0 — CBOW, 1 — Skip-gram),\n",
    "* sample — порог для downsampling'a высокочастотных слов,\n",
    "* workers — количество потоков,\n",
    "* alpha — learning rate,\n",
    "* iter — количество итераций,\n",
    "* max_vocab_size — позволяет выставить ограничение по памяти при создании словаря (т.е. если ограничение превышается, то низкочастотные слова будут выбрасываться). Для сравнения: 10 млн слов = 1Гб RAM.\n",
    "\n",
    "**Важно!** Обратите внимание, что тренировка модели не включает предобработку! Это значит, что избавляться от пунктуации, приводить слова к нижнему регистру, лемматизировать их, проставлять частеречные теги придется до тренировки модели (если, конечно, это необходимо для вашей задачи). Т.е. в каком виде слова будут в исходном тексте, в таком они будут и в модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "OB2FqIioX-r1",
    "outputId": "7a8840a9-a12b-4247-bf6b-b02c767ce2c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "CPU times: user 22.2 s, sys: 159 ms, total: 22.3 s\n",
      "Wall time: 6.19 s\n"
     ]
    }
   ],
   "source": [
    "print(\"Training model...\")\n",
    "\n",
    "%time model_en = word2vec.Word2Vec(flat_sentences, workers=4, vector_size=100, min_count=10, window=10, sample=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HFU6SYAZX-r3"
   },
   "source": [
    "Смотрим, сколько в модели слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HA3P0CUYX-r4",
    "outputId": "1bfec39d-aa30-4a4e-b77c-e8ed9c8c2571"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13761\n"
     ]
    }
   ],
   "source": [
    "print(len(model_en.wv.vectors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2mU9sbGYX-r8"
   },
   "source": [
    "Попробуем оценить модель вручную, аналогично тому, как проверяли предобученные модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "n8OQxmUyX-r9",
    "outputId": "4e4ab20e-31e4-4c02-fdfa-61b4ba8be133"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('actress', 0.8907668590545654)]\n"
     ]
    }
   ],
   "source": [
    "print(model_en.wv.most_similar(positive=[\"woman\", \"actor\"], negative=[\"man\"], topn=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('men', 0.6068826913833618)]\n"
     ]
    }
   ],
   "source": [
    "print(model_en.wv.most_similar(positive=[\"dogs\", \"man\"], negative=[\"dog\"], topn=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('italy', 0.8183871507644653), ('europe', 0.8170506954193115), ('japan', 0.7882201671600342)]\n"
     ]
    }
   ],
   "source": [
    "print(model_en.wv.most_similar(\"usa\", topn=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "novel\n"
     ]
    }
   ],
   "source": [
    "print(model_en.wv.doesnt_match(\"comedy thriller western novel\".split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Почему важно, на каких данных обучалась модель?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на ближайшие по смыслу слова к слову \"star\":\n",
    "- в модели, обученной на обзорах фильмов\n",
    "- в модели, обученной на Википедии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('stars', 0.6092053651809692)\n",
      "('hudson', 0.4575274586677551)\n",
      "('singer', 0.446683406829834)\n",
      "('stardom', 0.4426514506340027)\n",
      "('fame', 0.4368395209312439)\n",
      "('starred', 0.41369011998176575)\n",
      "('studded', 0.4064015746116638)\n",
      "('starring', 0.4028608202934265)\n",
      "('tyrone', 0.4026487469673157)\n",
      "('icon', 0.3995055556297302)\n"
     ]
    }
   ],
   "source": [
    "print(*model_en.wv.most_similar(\"star\", topn=10), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38832128"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_en.similarity('star', 'celebrity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16640092"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_en.similarity('star', 'sky')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20186296"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_en.similarity('star', 'shine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачаем предобученную модель fastText для английского:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "import fasttext.util\n",
    "#fasttext.util.download_model('en', if_exists='ignore') \n",
    "\n",
    "ft_eng = fasttext.load_model('cc.en.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.44439566]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity([ft_eng['star']], [ft_eng['celebrity']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.29363436]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity([ft_eng['star']], [ft_eng['sky']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.26306346]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity([ft_eng['star']], [ft_eng['shine']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "juR4NX0wX-r_"
   },
   "source": [
    "### Как дообучить существующую модель\n",
    "\n",
    "При тренировке модели \"с нуля\" веса инициализируются случайно, однако можно использовать для инициализации векторов веса из предобученной модели, таким образом как бы дообучая ее.\n",
    "\n",
    "Сначала посмотрим близость какой-нибудь пары слов в имеющейся модели, чтобы потом сравнить результат с дообученной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43382952"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_en.wv.similarity('white', 'rabbit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mxsz8DKMX-sD"
   },
   "source": [
    "В качестве дополнительных данных для обучения возьмем английский текст «Алисы в Зазеркалье»."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['through', 'the', 'looking-glass', 'by', 'lewis', 'carroll', 'chapter', 'i', 'looking-glass', 'house', 'one', 'thing', 'was', 'certain', 'that', 'the', 'white', 'kitten', 'had', 'had', 'nothing', 'to', 'do', 'with', 'it', '', 'it', 'was', 'the', 'black', 'kitten’s', 'fault', 'entirely'], ['for', 'the', 'white', 'kitten', 'had', 'been', 'having', 'its', 'face', 'washed', 'by', 'the', 'old', 'cat', 'for', 'the', 'last', 'quarter', 'of', 'an', 'hour', 'and', 'bearing', 'it', 'pretty', 'well', 'considering', 'so', 'you', 'see', 'that', 'it', 'couldn’t', 'have', 'had', 'any', 'hand', 'in', 'the', 'mischief']]\n"
     ]
    }
   ],
   "source": [
    "with open(\"alice.txt\", 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "text = re.sub('\\n', ' ', text)\n",
    "sents = sent_tokenize(text)\n",
    "\n",
    "punct = '!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~„“«»†*—/\\-‘’'\n",
    "clean_sents = []\n",
    "\n",
    "for sent in sents:\n",
    "    s = [w.lower().strip(punct) for w in sent.split()]\n",
    "    clean_sents.append(s)\n",
    "    \n",
    "print(clean_sents[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dH8f7GNBX-sK"
   },
   "source": [
    "Чтобы дообучить модель, надо сначала ее сохранить, а потом загрузить. Все параметры тренировки (размер вектора, мин. частота слова и т.п.) будут взяты из загруженной модели, т.е. задать их заново нельзя.\n",
    "\n",
    "**NB!** Дообучить можно только полную модель, а `KeyedVectors` — нельзя. Поэтому сохранять модель нужно в соотвествующем формате. Подробнее о разнице [вот тут](https://radimrehurek.com/gensim/models/keyedvectors.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "Rv--44TmX-sL",
    "outputId": "0973b4a0-dcbe-498e-86a5-28f6e9673aa4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    }
   ],
   "source": [
    "model_path = \"movie_reviews.model\"\n",
    "\n",
    "print(\"Saving model...\")\n",
    "model_en.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93627, 150225)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = word2vec.Word2Vec.load(model_path)\n",
    "\n",
    "model.build_vocab(clean_sents, update=True)\n",
    "model.train(clean_sents, total_examples=model.corpus_count, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nMLhISWiX-sS"
   },
   "source": [
    "\"Белый\" и \"кролик\" стали ближе друг к другу!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44453424"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('white', 'rabbit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Как обучить свою модель: fastText\n",
    "\n",
    "Выше мы записали предобработанные данные IMDB в текстовый файл, теперь мы можем использовать его для обучения модели fastText."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'fasttext' has no attribute 'train_unsupervised'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sz/c3kzvnt14rlgyfdclllygz9w0000gn/T/ipykernel_56548/3083572920.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# так можно обучить свою модель\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mft_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfasttext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_unsupervised\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'clean_text.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'fasttext' has no attribute 'train_unsupervised'"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "\n",
    "# так можно обучить свою модель \n",
    "ft_model = fasttext.train_unsupervised('clean_text.txt', minn=3, maxn=4, dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.10647972,  0.00348743,  0.00400553, -0.2220917 ,  0.02774876,\n",
       "        0.28113014,  0.04588589, -0.00953584, -0.14305185,  0.06663238,\n",
       "       -0.01932244,  0.06766095, -0.06964523, -0.00879823, -0.2754987 ,\n",
       "        0.00865352, -0.02323557, -0.25205076, -0.12951218,  0.03342189,\n",
       "        0.00371615, -0.05362495,  0.01820608,  0.1001416 , -0.00959393,\n",
       "       -0.18463574,  0.3780635 , -0.02545302, -0.18444885,  0.12707062,\n",
       "       -0.10905846,  0.16443293,  0.15409584, -0.11409819,  0.24385491,\n",
       "       -0.00680395, -0.17201523, -0.11899467, -0.1555182 , -0.09888287,\n",
       "       -0.0370929 ,  0.07110037, -0.18011254, -0.13228868,  0.06374579,\n",
       "        0.11771804,  0.12609613, -0.0567237 ,  0.18499018,  0.1786773 ,\n",
       "        0.14431344, -0.04145625, -0.05425412, -0.19320773, -0.00719959,\n",
       "       -0.13159607, -0.15365084, -0.0127184 ,  0.0429236 , -0.0468537 ,\n",
       "       -0.16655543,  0.14787091,  0.00640271,  0.10557158,  0.3033813 ,\n",
       "        0.21118031,  0.0810559 , -0.15322076,  0.05768304,  0.03156255,\n",
       "        0.08934344, -0.17603667, -0.28397682,  0.02493125,  0.12160244,\n",
       "        0.07438196,  0.02870641,  0.15328582, -0.2951915 ,  0.11127534,\n",
       "        0.22485904,  0.05506345,  0.23298828, -0.12812184,  0.0363166 ,\n",
       "       -0.11760419, -0.2728406 ,  0.06310979,  0.0163185 , -0.00276489,\n",
       "       -0.14891374,  0.05296465, -0.06690532,  0.12462053, -0.13946794,\n",
       "       -0.23445657, -0.00574374,  0.15062457, -0.00894643, -0.01967534,\n",
       "       -0.07374644,  0.00181053, -0.03458458, -0.0748456 ,  0.16700003,\n",
       "        0.12362601, -0.09110783, -0.05691807,  0.03763324, -0.0379038 ,\n",
       "       -0.0340135 ,  0.01718459, -0.00142723,  0.06471407,  0.14001875,\n",
       "       -0.01078935,  0.2020977 ,  0.02244384, -0.01641017,  0.03489206,\n",
       "       -0.03143051,  0.06208009, -0.01247452,  0.02434204,  0.0880824 ,\n",
       "        0.1341468 , -0.03408279, -0.03738172,  0.11721347, -0.0487804 ,\n",
       "        0.04758214, -0.19982706,  0.15834196, -0.05561088,  0.19729088,\n",
       "       -0.21621099, -0.00298688, -0.09032749, -0.03335881,  0.06356947,\n",
       "       -0.00336576,  0.15146399, -0.17335647, -0.0827271 , -0.14458625,\n",
       "       -0.36312377,  0.12627144, -0.0016868 ,  0.09096746,  0.02144508,\n",
       "       -0.00956393, -0.18888775,  0.02414494,  0.12479188,  0.1224603 ,\n",
       "        0.13554408, -0.10544685,  0.18642114,  0.12462015,  0.14837256,\n",
       "        0.13810405, -0.10096337, -0.07447851, -0.04384645,  0.00678429,\n",
       "        0.0138451 ,  0.03518347, -0.25854912, -0.10484967, -0.03255135,\n",
       "        0.02545583,  0.00079106,  0.04044076,  0.3164993 ,  0.04806856,\n",
       "       -0.01576148,  0.11982085, -0.23312406, -0.07089883,  0.08599098,\n",
       "       -0.0584241 ,  0.21747057,  0.01652784, -0.04547612, -0.00425825,\n",
       "        0.08570202, -0.10009172, -0.01164426, -0.13189556, -0.03768274,\n",
       "       -0.11670502, -0.13645473,  0.23310612, -0.11002111, -0.04876021,\n",
       "        0.23654036, -0.17239796, -0.06510314, -0.11531647, -0.07209118,\n",
       "        0.08668107,  0.14282747, -0.12921567, -0.01978053,  0.01892957,\n",
       "       -0.17166983, -0.03767522, -0.04455657, -0.12475715,  0.1205698 ,\n",
       "       -0.0223694 ,  0.17989808, -0.2546117 , -0.1500342 , -0.17565282,\n",
       "        0.11773366,  0.01775845, -0.06116071,  0.0283902 ,  0.03569905,\n",
       "        0.25115395,  0.02294705, -0.05371798,  0.03680886,  0.13164642,\n",
       "        0.09370206,  0.1172943 ,  0.22707926,  0.06699484,  0.14266716,\n",
       "       -0.13867424,  0.09012312, -0.02852494, -0.19918357, -0.09251253,\n",
       "       -0.20748758, -0.18582642,  0.08112054,  0.00262597,  0.0477021 ,\n",
       "        0.10119045,  0.09308492, -0.07188187,  0.24025121,  0.16576168,\n",
       "       -0.21916008,  0.23559944, -0.03360926,  0.23927112,  0.06010748,\n",
       "       -0.10249438,  0.14544252,  0.12475874, -0.26403013, -0.08486622,\n",
       "       -0.18960364, -0.02308721, -0.00917426, -0.05708581, -0.18267463,\n",
       "        0.20308118, -0.13605209,  0.29976863, -0.15766624, -0.12814009,\n",
       "        0.04926346, -0.03348718, -0.03875241, -0.17668977, -0.09978857,\n",
       "        0.17115428,  0.19755273,  0.01411418, -0.06554732, -0.19383872,\n",
       "       -0.06060887,  0.02333008,  0.23856847, -0.03785389, -0.03472081,\n",
       "        0.3516929 , -0.06610451,  0.2795676 , -0.00958802, -0.05536084,\n",
       "       -0.00367441,  0.00242285, -0.19740188, -0.1464423 , -0.00957965,\n",
       "       -0.16542217, -0.05397834,  0.00693617, -0.19925623,  0.04394748,\n",
       "        0.16893867, -0.01976188,  0.19094467, -0.11328156, -0.19202887],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_model.get_word_vector(\"movie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "TsZnXqH8X-st",
    "outputId": "983fcc63-9a13-43fb-a4be-3dfd55d70863"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.6824725270271301, 'charactor'),\n",
       " (0.6627753973007202, 'ctor'),\n",
       " (0.6476548314094543, 'actors'),\n",
       " (0.630966067314148, 'tractor'),\n",
       " (0.5709237456321716, 'actress'),\n",
       " (0.5643734931945801, 'reactor'),\n",
       " (0.5564367771148682, 'benefactor'),\n",
       " (0.5310477018356323, 'hector'),\n",
       " (0.5144302845001221, 'contractor'),\n",
       " (0.5066649913787842, 'factor')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_model.get_nearest_neighbors('actor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "iKR3FzCFX-sv",
    "outputId": "a673203f-8cd8-4dc1-b4fd-79b8f8fe83cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.6606210470199585, 'actress'),\n",
       " (0.5363813042640686, 'actresses'),\n",
       " (0.48164188861846924, 'ctor'),\n",
       " (0.4782077372074127, 'actors'),\n",
       " (0.46812912821769714, 'charactor'),\n",
       " (0.4576756954193115, 'seductress'),\n",
       " (0.4522528052330017, 'tractor'),\n",
       " (0.4366052448749542, 'hector'),\n",
       " (0.42155134677886963, 'womaniser'),\n",
       " (0.40410301089286804, 'abductor')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_model.get_analogies(\"woman\", \"man\", \"actor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OOV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "ttAgMPC_X-sx",
    "outputId": "9bbec1ad-d83a-4e75-df98-94356598a671"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.7510600090026855, 'actresses'),\n",
       " (0.747826099395752, 'actress'),\n",
       " (0.6713401675224304, 'actors'),\n",
       " (0.6301003098487854, 'actor'),\n",
       " (0.50783771276474, 'acting'),\n",
       " (0.4529079794883728, 'xd'),\n",
       " (0.4442768394947052, 'gzsz'),\n",
       " (0.44143927097320557, 'act'),\n",
       " (0.4292294681072235, 'acharya'),\n",
       " (0.42825278639793396, 'nb')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_model.get_nearest_neighbors('actr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "V9alEdz0X-s0",
    "outputId": "1126182a-8abd-471c-9346-59e852625c22",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.6236038208007812, 'eek'),\n",
       " (0.612317681312561, 'movie'),\n",
       " (0.5866702795028687, 'geek'),\n",
       " (0.5764365792274475, 'moviegoer'),\n",
       " (0.571036696434021, 'moviemaking'),\n",
       " (0.5661671161651611, 'movies'),\n",
       " (0.5481372475624084, 'creek'),\n",
       " (0.5346364974975586, 'moviegoers'),\n",
       " (0.5314581394195557, 'cq'),\n",
       " (0.5229887366294861, 'bwp')]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_model.get_nearest_neighbors('moviegeek')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CXKnPffPX-sY"
   },
   "source": [
    "## Оценка\n",
    "\n",
    "Мы научились обучать модели, научились загружать готовые, а как понять, какая модель лучше? Или вот, например, мы обучили модель, а как понять, насколько она хорошая? Рассмотрим два метода: с помощью метрик, основанных на подготовленных данных, и визуализации.\n",
    "\n",
    "Для этого существуют специальные наборы данных для оценки качества дистрибутивных моделей. Основных два: один измеряет точность решения задач на аналогии (про Сибирь и пельмени), а второй используется для оценки коэффициента семантической близости. \n",
    "\n",
    "### Word Similarity\n",
    "\n",
    "Этот метод заключается в том, чтобы оценить, насколько представления о семантической близости слов в модели соотносятся с \"представлениями\" людей.\n",
    "\n",
    "| слово 1    | слово 2    | близость | \n",
    "|------------|------------|----------|\n",
    "| кошка      | собака     | 0.7      |  \n",
    "| чашка      | кружка     | 0.9      |       \n",
    "\n",
    "Для каждой пары слов из заранее заданного набора данных мы можем посчитать косинусное расстояние, и получить список таких значений близости. При этом у нас уже есть список значений близостей, сделанный людьми. Мы можем сравнить эти два списка и понять, насколько они похожи (например, посчитав корреляцию). Эта мера схожести должна говорить о том, насколько модель хорошо моделирует расстояния до слова.\n",
    "\n",
    "### Аналогии\n",
    "\n",
    "Другая популярная задача для \"внутренней\" оценки называется задачей поиска аналогий. Как мы уже разбирали выше, с помощью простых арифметических операций мы можем модифицировать значение слова. Если заранее собрать набор слов-модификаторов, а также слов, которые мы хотим получить в результаты модификации, то на основе подсчёта количества \"попаданий\" в желаемое слово мы можем оценить, насколько хорошо работает модель.\n",
    "\n",
    "В качестве слов-модификаторов мы можем использовать семантические аналогии. Скажем, если у нас есть некоторое отношение \"страна-столица\", то для оценки модели мы можем использовать пары наподобие \"Россия-Москва\", \"Норвегия-Осло\", и т.д. Набор данных будет выглядеть следующм образом:\n",
    "\n",
    "| слово 1    | слово 2    | отношение     | \n",
    "|------------|------------|---------------|\n",
    "| Россия     | Москва     | страна-столица|  \n",
    "| Норвегия   | Осло       | страна-столица|\n",
    "\n",
    "Рассматривая случайные две пары из этого набора, мы хотим, имея триплет (Россия, Москва, Норвегия) хотим получить слово \"Осло\", т.е. найти такое слово, которое будет находиться в том же отношении со словом \"Норвегия\", как \"Россия\" находится с Москвой. \n",
    "\n",
    "Данные для русского языка можно скачать на странице с моделями на RusVectores. Посчитаем качество нашей модели НКРЯ на датасете про аналогии:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "z54TWXlcX-sb",
    "outputId": "8f0e238a-4944-4331-b68e-6535923f9a17"
   },
   "outputs": [],
   "source": [
    "res = model_ru.accuracy('ru_analogy_tagged.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": capital-common-countries\n",
      "афины_S греция_S багдад_S ирак_S\n",
      "афины_S греция_S бангкок_S таиланд_S\n",
      "афины_S греция_S пекин_S китай_S\n",
      "афины_S греция_S берлин_S германия_S\n",
      "афины_S греция_S берн_S швейцария_S\n",
      "афины_S греция_S каир_S египет_S\n",
      "афины_S греция_S канберра_S австралия_S\n",
      "афины_S греция_S ханой_S вьетнам_S\n",
      "афины_S греция_S гавана_S куба_S\n",
      "афины_S греция_S хельсинки_S финляндия_S\n",
      "афины_S греция_S исламабад_S пакистан_S\n",
      "афины_S греция_S кабул_S афганистан_S\n",
      "афины_S греция_S лондон_S англия_S\n",
      "афины_S греция_S мадрид_S испания_S\n",
      "афины_S греция_S москва_S россия_S\n",
      "афины_S греция_S осло_S норвегия_S\n",
      "афины_S греция_S оттава_S канада_S\n",
      "афины_S греция_S париж_S франция_S\n",
      "афины_S греция_S рим_S италия_S\n",
      "афины_S греция_S стокгольм_S швеция_S\n",
      "афины_S греция_S тегеран_S иран_S\n",
      "афины_S греция_S токио_S япония_S\n",
      "\u001b[Kбагдад_S ирак_S бангкок_S таиланд_S\n",
      ":\u001b[K"
     ]
    }
   ],
   "source": [
    "!less ru_analogy_tagged.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "tWNppFBeX-sd",
    "outputId": "8d2a2fdf-0d2d-4963-9d68-544caf08c773"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('МАЛЬЧИК_S', 'ДЕВОЧКА_S', 'ДЕД_S', 'БАБКА_S'), ('МАЛЬЧИК_S', 'ДЕВОЧКА_S', 'КОРОЛЬ_S', 'КОРОЛЕВА_S'), ('МАЛЬЧИК_S', 'ДЕВОЧКА_S', 'ПРИНЦ_S', 'ПРИНЦЕССА_S'), ('МАЛЬЧИК_S', 'ДЕВОЧКА_S', 'ОТЧИМ_S', 'МАЧЕХА_S'), ('МАЛЬЧИК_S', 'ДЕВОЧКА_S', 'ПАСЫНОК_S', 'ПАДЧЕРИЦА_S'), ('БРАТ_S', 'СЕСТРА_S', 'ДЕД_S', 'БАБКА_S'), ('БРАТ_S', 'СЕСТРА_S', 'ОТЧИМ_S', 'МАЧЕХА_S'), ('БРАТ_S', 'СЕСТРА_S', 'ПАСЫНОК_S', 'ПАДЧЕРИЦА_S'), ('ПАПА_S', 'МАМА_S', 'ДЕД_S', 'БАБКА_S'), ('ПАПА_S', 'МАМА_S', 'ОТЧИМ_S', 'МАЧЕХА_S')]\n"
     ]
    }
   ],
   "source": [
    "print(res[4]['incorrect'][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "бабушка_S\n"
     ]
    }
   ],
   "source": [
    "print(model_ru.most_similar(positive=['мальчик_S', 'бабка_S'], negative=['девочка_S'])[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88, 218)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res[4]['incorrect']), len(res[4]['correct'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sv0wxUXIX-se"
   },
   "source": [
    "## Визуализация\n",
    "\n",
    "На полученную модель можно посмотреть, визуализировав ее, например, на плоскости.\n",
    "### t-SNE\n",
    "\n",
    "**t-SNE**  (*t-distributed Stochastic Neighbor Embedding*) — техника нелинейного снижения размерности и визуализации многомерных переменных. Она разработана специально для данных высокой размерности Л. ван дер Маатеном и Д. Хинтоном, [вот их статья](http://jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf). t-SNE — это итеративный алгоритм, основанный на вычислении попарных расстояний между всеми объектами (в том числе поэтому он довольно медленный).\n",
    "\n",
    "\n",
    "Изобразим на плоскости 1000 самых частотных слов из коллекции текстов про кино:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"movie_reviews.model\"\n",
    "\n",
    "model = word2vec.Word2Vec.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "5UH91gFyX-sf",
    "outputId": "91b0537a-6e9b-47af-c462-9c09e7f8df4b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89f2ebecd1e04c2fb5348b40293290fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132111 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'and', 'a', 'of', 'to', 'is', 'in', 'it', 'i', 'that', 'this', 's', 'as', 'with', 'for', 'was', 'film', 'but', 'movie', 'his', 'on', 'you', 'he', 'are', 'not', 't', 'one', 'have', 'be', 'by', 'all', 'who', 'an', 'at', 'from', 'her', 'they', 'has', 'so', 'like', 'about', 'very', 'out', 'there', 'she', 'what', 'or', 'good', 'more', 'when']\n"
     ]
    }
   ],
   "source": [
    "from nltk import FreqDist\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "top_words = []\n",
    "\n",
    "\n",
    "fd = FreqDist()\n",
    "for s in tqdm(flat_sentences):\n",
    "    fd.update(s)\n",
    "\n",
    "for w in fd.most_common(1000):\n",
    "    top_words.append(w[0])\n",
    "    \n",
    "print(top_words[:50:])\n",
    "top_words_vec = [model.wv[word] for word in top_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "74FvTsuuX-sg",
    "outputId": "0f629f24-1cd1-471a-9f1f-129792c28e1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 25s, sys: 3.39 s, total: 1min 28s\n",
      "Wall time: 2min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "top_words_tsne = tsne.fit_transform(top_words_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "colab_type": "code",
    "id": "R0A__XKwX-si",
    "outputId": "6e212d18-d4bd-4dce-fcf4-4ddf1e1627ec"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1002\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  const JS_MIME_TYPE = 'application/javascript';\n",
       "  const HTML_MIME_TYPE = 'text/html';\n",
       "  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  const CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    const script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    const cell = handle.cell;\n",
       "\n",
       "    const id = cell.output_area._bokeh_element_id;\n",
       "    const server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd_clean, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            const id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd_destroy);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    const output_area = handle.output_area;\n",
       "    const output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      const bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      const script_attrs = bk_div.children[0].attributes;\n",
       "      for (let i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      const toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    const events = require('base/js/events');\n",
       "    const OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  const NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    const el = document.getElementById(\"1002\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.1.min.js\"];\n",
       "  const css_urls = [];\n",
       "  \n",
       "\n",
       "  const inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (let i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      const cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"1002\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.1.min.js\"];\n  const css_urls = [];\n  \n\n  const inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"8342fcfe-4b62-479e-bd80-23c500af35c5\" data-root-id=\"1003\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  const docs_json = {\"11d6b2fd-edf9-46d3-ab8a-9f347d6a7d6b\":{\"defs\":[],\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1014\"}],\"center\":[{\"id\":\"1017\"},{\"id\":\"1021\"},{\"id\":\"1038\"}],\"left\":[{\"id\":\"1018\"}],\"renderers\":[{\"id\":\"1036\"}],\"title\":{\"id\":\"1004\"},\"toolbar\":{\"id\":\"1026\"},\"toolbar_location\":\"above\",\"x_range\":{\"id\":\"1006\"},\"x_scale\":{\"id\":\"1010\"},\"y_range\":{\"id\":\"1008\"},\"y_scale\":{\"id\":\"1012\"}},\"id\":\"1003\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"tools\":[{\"id\":\"1022\"},{\"id\":\"1023\"},{\"id\":\"1024\"},{\"id\":\"1025\"}]},\"id\":\"1026\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"1042\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1043\",\"type\":\"AllLabels\"},{\"attributes\":{\"fill_color\":{\"value\":\"#1f77b4\"},\"line_color\":{\"value\":\"#1f77b4\"},\"size\":{\"value\":8},\"x\":{\"field\":\"x1\"},\"y\":{\"field\":\"x2\"}},\"id\":\"1033\",\"type\":\"Scatter\"},{\"attributes\":{},\"id\":\"1045\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"coordinates\":null,\"formatter\":{\"id\":\"1042\"},\"group\":null,\"major_label_policy\":{\"id\":\"1043\"},\"ticker\":{\"id\":\"1019\"}},\"id\":\"1018\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1046\",\"type\":\"AllLabels\"},{\"attributes\":{},\"id\":\"1006\",\"type\":\"DataRange1d\"},{\"attributes\":{\"coordinates\":null,\"group\":null,\"source\":{\"id\":\"1031\"},\"text\":{\"field\":\"names\"},\"text_align\":{\"value\":\"center\"},\"text_color\":{\"value\":\"#555555\"},\"text_font_size\":{\"value\":\"8pt\"},\"x\":{\"field\":\"x1\"},\"y\":{\"field\":\"x2\"},\"y_offset\":{\"value\":6}},\"id\":\"1038\",\"type\":\"LabelSet\"},{\"attributes\":{},\"id\":\"1012\",\"type\":\"LinearScale\"},{\"attributes\":{\"coordinates\":null,\"data_source\":{\"id\":\"1031\"},\"glyph\":{\"id\":\"1033\"},\"group\":null,\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"1035\"},\"nonselection_glyph\":{\"id\":\"1034\"},\"view\":{\"id\":\"1037\"}},\"id\":\"1036\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"axis\":{\"id\":\"1018\"},\"coordinates\":null,\"dimension\":1,\"group\":null,\"ticker\":null},\"id\":\"1021\",\"type\":\"Grid\"},{\"attributes\":{\"coordinates\":null,\"group\":null,\"text\":\"word2vec T-SNE (eng model, top1000 words)\"},\"id\":\"1004\",\"type\":\"Title\"},{\"attributes\":{},\"id\":\"1019\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1015\",\"type\":\"BasicTicker\"},{\"attributes\":{\"axis\":{\"id\":\"1014\"},\"coordinates\":null,\"group\":null,\"ticker\":null},\"id\":\"1017\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1024\",\"type\":\"ResetTool\"},{\"attributes\":{},\"id\":\"1010\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1022\",\"type\":\"PanTool\"},{\"attributes\":{},\"id\":\"1023\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"coordinates\":null,\"formatter\":{\"id\":\"1045\"},\"group\":null,\"major_label_policy\":{\"id\":\"1046\"},\"ticker\":{\"id\":\"1015\"}},\"id\":\"1014\",\"type\":\"LinearAxis\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"hatch_alpha\":{\"value\":0.1},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"size\":{\"value\":8},\"x\":{\"field\":\"x1\"},\"y\":{\"field\":\"x2\"}},\"id\":\"1034\",\"type\":\"Scatter\"},{\"attributes\":{},\"id\":\"1047\",\"type\":\"UnionRenderers\"},{\"attributes\":{},\"id\":\"1025\",\"type\":\"SaveTool\"},{\"attributes\":{},\"id\":\"1048\",\"type\":\"Selection\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.2},\"fill_color\":{\"value\":\"#1f77b4\"},\"hatch_alpha\":{\"value\":0.2},\"line_alpha\":{\"value\":0.2},\"line_color\":{\"value\":\"#1f77b4\"},\"size\":{\"value\":8},\"x\":{\"field\":\"x1\"},\"y\":{\"field\":\"x2\"}},\"id\":\"1035\",\"type\":\"Scatter\"},{\"attributes\":{},\"id\":\"1008\",\"type\":\"DataRange1d\"},{\"attributes\":{\"source\":{\"id\":\"1031\"}},\"id\":\"1037\",\"type\":\"CDSView\"},{\"attributes\":{\"data\":{\"names\":[\"the\",\"and\",\"a\",\"of\",\"to\",\"is\",\"in\",\"it\",\"i\",\"that\",\"this\",\"s\",\"as\",\"with\",\"for\",\"was\",\"film\",\"but\",\"movie\",\"his\",\"on\",\"you\",\"he\",\"are\",\"not\",\"t\",\"one\",\"have\",\"be\",\"by\",\"all\",\"who\",\"an\",\"at\",\"from\",\"her\",\"they\",\"has\",\"so\",\"like\",\"about\",\"very\",\"out\",\"there\",\"she\",\"what\",\"or\",\"good\",\"more\",\"when\",\"some\",\"if\",\"just\",\"can\",\"story\",\"time\",\"my\",\"great\",\"well\",\"up\",\"which\",\"their\",\"see\",\"also\",\"we\",\"really\",\"would\",\"will\",\"me\",\"had\",\"only\",\"him\",\"even\",\"most\",\"other\",\"were\",\"first\",\"than\",\"much\",\"its\",\"no\",\"into\",\"people\",\"best\",\"love\",\"get\",\"how\",\"life\",\"been\",\"because\",\"way\",\"do\",\"made\",\"films\",\"them\",\"after\",\"many\",\"two\",\"too\",\"think\",\"movies\",\"characters\",\"character\",\"don\",\"man\",\"show\",\"watch\",\"seen\",\"then\",\"still\",\"little\",\"make\",\"could\",\"never\",\"being\",\"where\",\"does\",\"over\",\"any\",\"while\",\"know\",\"did\",\"years\",\"here\",\"ever\",\"end\",\"these\",\"such\",\"real\",\"scene\",\"back\",\"those\",\"though\",\"off\",\"new\",\"your\",\"go\",\"acting\",\"plot\",\"world\",\"scenes\",\"say\",\"through\",\"makes\",\"better\",\"now\",\"work\",\"young\",\"ve\",\"old\",\"find\",\"both\",\"before\",\"us\",\"again\",\"series\",\"quite\",\"something\",\"cast\",\"should\",\"part\",\"always\",\"lot\",\"another\",\"actors\",\"m\",\"director\",\"family\",\"own\",\"between\",\"may\",\"same\",\"role\",\"watching\",\"every\",\"funny\",\"doesn\",\"re\",\"performance\",\"few\",\"bad\",\"look\",\"why\",\"things\",\"times\",\"big\",\"however\",\"actually\",\"action\",\"going\",\"bit\",\"down\",\"comedy\",\"music\",\"must\",\"take\",\"saw\",\"long\",\"fun\",\"right\",\"fact\",\"excellent\",\"didn\",\"around\",\"without\",\"thing\",\"thought\",\"got\",\"each\",\"day\",\"feel\",\"seems\",\"come\",\"done\",\"beautiful\",\"especially\",\"played\",\"almost\",\"want\",\"yet\",\"give\",\"pretty\",\"last\",\"since\",\"different\",\"although\",\"gets\",\"true\",\"interesting\",\"job\",\"our\",\"enough\",\"shows\",\"horror\",\"woman\",\"tv\",\"probably\",\"father\",\"original\",\"girl\",\"d\",\"point\",\"plays\",\"wonderful\",\"far\",\"course\",\"john\",\"rather\",\"isn\",\"ll\",\"later\",\"dvd\",\"whole\",\"war\",\"away\",\"found\",\"screen\",\"nothing\",\"year\",\"once\",\"hard\",\"together\",\"am\",\"set\",\"having\",\"making\",\"place\",\"might\",\"comes\",\"sure\",\"american\",\"play\",\"kind\",\"perfect\",\"takes\",\"performances\",\"himself\",\"worth\",\"everyone\",\"anyone\",\"actor\",\"three\",\"wife\",\"classic\",\"goes\",\"ending\",\"version\",\"star\",\"enjoy\",\"book\",\"nice\",\"everything\",\"during\",\"put\",\"seeing\",\"least\",\"house\",\"high\",\"watched\",\"loved\",\"men\",\"night\",\"anything\",\"believe\",\"guy\",\"top\",\"amazing\",\"hollywood\",\"looking\",\"main\",\"definitely\",\"gives\",\"home\",\"seem\",\"episode\",\"audience\",\"sense\",\"truly\",\"special\",\"second\",\"fan\",\"short\",\"mind\",\"human\",\"recommend\",\"black\",\"full\",\"help\",\"along\",\"trying\",\"small\",\"death\",\"friends\",\"remember\",\"often\",\"said\",\"favorite\",\"heart\",\"let\",\"early\",\"until\",\"left\",\"script\",\"maybe\",\"less\",\"live\",\"today\",\"moments\",\"others\",\"brilliant\",\"shot\",\"liked\",\"won\",\"become\",\"used\",\"style\",\"mother\",\"came\",\"lives\",\"stars\",\"cinema\",\"looks\",\"perhaps\",\"read\",\"enjoyed\",\"boy\",\"drama\",\"highly\",\"given\",\"playing\",\"use\",\"women\",\"next\",\"fine\",\"effects\",\"kids\",\"line\",\"need\",\"entertaining\",\"someone\",\"works\",\"mr\",\"simply\",\"children\",\"picture\",\"face\",\"keep\",\"friend\",\"dark\",\"overall\",\"minutes\",\"certainly\",\"wasn\",\"history\",\"finally\",\"couple\",\"against\",\"son\",\"lost\",\"understand\",\"michael\",\"else\",\"throughout\",\"fans\",\"city\",\"reason\",\"written\",\"production\",\"several\",\"school\",\"based\",\"rest\",\"try\",\"dead\",\"hope\",\"strong\",\"white\",\"tell\",\"itself\",\"half\",\"person\",\"sometimes\",\"past\",\"start\",\"genre\",\"final\",\"town\",\"beginning\",\"art\",\"humor\",\"yes\",\"idea\",\"game\",\"late\",\"becomes\",\"despite\",\"case\",\"able\",\"money\",\"child\",\"completely\",\"side\",\"camera\",\"getting\",\"instead\",\"soon\",\"under\",\"age\",\"viewer\",\"stories\",\"days\",\"simple\",\"felt\",\"roles\",\"video\",\"either\",\"name\",\"doing\",\"turns\",\"close\",\"wants\",\"wrong\",\"went\",\"james\",\"title\",\"evil\",\"budget\",\"episodes\",\"relationship\",\"fantastic\",\"piece\",\"david\",\"turn\",\"brother\",\"murder\",\"parts\",\"absolutely\",\"head\",\"experience\",\"eyes\",\"direction\",\"sex\",\"called\",\"directed\",\"lines\",\"behind\",\"sort\",\"actress\",\"lead\",\"example\",\"oscar\",\"including\",\"musical\",\"known\",\"score\",\"hit\",\"chance\",\"feeling\",\"already\",\"voice\",\"living\",\"moment\",\"supporting\",\"low\",\"ago\",\"themselves\",\"hilarious\",\"reality\",\"jack\",\"told\",\"song\",\"hand\",\"moving\",\"quality\",\"dialogue\",\"happy\",\"matter\",\"paul\",\"light\",\"future\",\"entire\",\"finds\",\"gave\",\"laugh\",\"released\",\"expect\",\"fight\",\"particularly\",\"police\",\"cinematography\",\"sound\",\"type\",\"whose\",\"enjoyable\",\"view\",\"husband\",\"number\",\"daughter\",\"documentary\",\"self\",\"romantic\",\"superb\",\"robert\",\"modern\",\"took\",\"mean\",\"shown\",\"coming\",\"important\",\"leave\",\"king\",\"change\",\"somewhat\",\"wanted\",\"tells\",\"country\",\"career\",\"events\",\"run\",\"heard\",\"girls\",\"season\",\"greatest\",\"etc\",\"care\",\"starts\",\"b\",\"english\",\"tale\",\"killer\",\"totally\",\"animation\",\"guys\",\"usual\",\"miss\",\"opinion\",\"violence\",\"easy\",\"songs\",\"british\",\"says\",\"writing\",\"realistic\",\"writer\",\"act\",\"comic\",\"thriller\",\"television\",\"power\",\"ones\",\"kid\",\"novel\",\"problem\",\"alone\",\"york\",\"attention\",\"involved\",\"kill\",\"extremely\",\"seemed\",\"hero\",\"rock\",\"french\",\"stuff\",\"o\",\"wish\",\"sad\",\"begins\",\"ways\",\"taken\",\"richard\",\"knows\",\"atmosphere\",\"car\",\"taking\",\"similar\",\"perfectly\",\"surprised\",\"eye\",\"room\",\"across\",\"order\",\"sequence\",\"team\",\"powerful\",\"serious\",\"among\",\"due\",\"george\",\"strange\",\"cannot\",\"beauty\",\"famous\",\"herself\",\"myself\",\"tries\",\"happened\",\"class\",\"four\",\"cool\",\"anyway\",\"release\",\"theme\",\"opening\",\"entertainment\",\"ends\",\"exactly\",\"slow\",\"unique\",\"level\",\"red\",\"easily\",\"interest\",\"happen\",\"crime\",\"viewing\",\"memorable\",\"sets\",\"group\",\"stop\",\"message\",\"nature\",\"working\",\"sister\",\"dance\",\"problems\",\"knew\",\"mystery\",\"bring\",\"brought\",\"believable\",\"mostly\",\"thinking\",\"couldn\",\"disney\",\"within\",\"lady\",\"peter\",\"blood\",\"society\",\"parents\",\"upon\",\"meets\",\"soundtrack\",\"viewers\",\"usually\",\"form\",\"tom\",\"local\",\"certain\",\"follow\",\"whether\",\"possible\",\"emotional\",\"de\",\"killed\",\"middle\",\"above\",\"god\",\"needs\",\"happens\",\"flick\",\"haven\",\"masterpiece\",\"major\",\"period\",\"named\",\"particular\",\"th\",\"feature\",\"earth\",\"stand\",\"typical\",\"words\",\"elements\",\"obviously\",\"romance\",\"jane\",\"showing\",\"yourself\",\"e\",\"brings\",\"fantasy\",\"america\",\"guess\",\"huge\",\"unfortunately\",\"running\",\"indeed\",\"talent\",\"stage\",\"started\",\"leads\",\"sweet\",\"poor\",\"deal\",\"japanese\",\"incredible\",\"personal\",\"fast\",\"deep\",\"hours\",\"became\",\"nearly\",\"dream\",\"giving\",\"clearly\",\"turned\",\"near\",\"surprise\",\"obvious\",\"cut\",\"era\",\"body\",\"hour\",\"female\",\"five\",\"note\",\"learn\",\"truth\",\"except\",\"feels\",\"tony\",\"lots\",\"complete\",\"filmed\",\"clear\",\"street\",\"keeps\",\"older\",\"eventually\",\"buy\",\"william\",\"stewart\",\"match\",\"joe\",\"unlike\",\"meet\",\"fall\",\"shots\",\"difficult\",\"means\",\"talking\",\"rating\",\"dramatic\",\"wonder\",\"situation\",\"appears\",\"present\",\"subject\",\"comments\",\"general\",\"sequences\",\"lee\",\"points\",\"earlier\",\"gone\",\"ten\",\"recommended\",\"third\",\"business\",\"suspense\",\"beyond\",\"talk\",\"leaves\",\"portrayal\",\"beautifully\",\"bill\",\"single\",\"plenty\",\"check\",\"word\",\"falls\",\"whom\",\"non\",\"return\",\"figure\",\"battle\",\"scary\",\"using\",\"doubt\",\"add\",\"solid\",\"hear\",\"success\",\"hell\",\"touching\",\"oh\",\"jokes\",\"boys\",\"awesome\",\"political\",\"wouldn\",\"dog\",\"recently\",\"sexual\",\"straight\",\"features\",\"please\",\"setting\",\"lack\",\"forget\",\"mark\",\"married\",\"social\",\"adventure\",\"interested\",\"brothers\",\"actual\",\"sees\",\"terrific\",\"move\",\"call\",\"theater\",\"dr\",\"western\",\"animated\",\"various\",\"baby\",\"space\",\"leading\",\"disappointed\",\"portrayed\",\"aren\",\"smith\",\"screenplay\",\"hate\",\"towards\",\"noir\",\"decent\",\"outstanding\",\"journey\",\"none\",\"kelly\",\"looked\",\"effective\",\"directors\",\"caught\",\"cold\",\"sci\",\"fi\",\"storyline\",\"mary\",\"charming\",\"rich\",\"popular\",\"manages\",\"rare\",\"harry\",\"spirit\",\"appreciate\",\"open\",\"moves\",\"acted\",\"basically\",\"subtle\",\"century\",\"boring\",\"mention\",\"inside\",\"deserves\",\"background\",\"pace\",\"familiar\",\"ben\",\"creepy\",\"supposed\",\"secret\",\"die\",\"jim\",\"natural\",\"question\",\"effect\",\"impressive\",\"rate\",\"saying\",\"realize\",\"language\",\"intelligent\",\"material\",\"telling\",\"singing\",\"scott\",\"imagine\",\"visual\",\"adult\",\"office\",\"kept\",\"dancing\",\"uses\",\"hot\",\"stunning\",\"pure\",\"seriously\",\"wait\",\"copy\",\"previous\",\"reading\",\"magic\",\"escape\",\"create\",\"created\",\"review\",\"somehow\",\"crazy\",\"air\",\"stay\",\"attempt\",\"hands\",\"frank\",\"filled\",\"expected\",\"surprisingly\",\"average\",\"successful\",\"complex\",\"studio\",\"quickly\",\"plus\",\"c\",\"male\",\"images\",\"exciting\",\"following\",\"minute\",\"reasons\",\"follows\",\"members\",\"casting\",\"co\",\"themes\",\"german\",\"touch\",\"edge\",\"free\",\"genius\",\"cute\",\"admit\",\"reviews\",\"ok\",\"younger\",\"outside\",\"fighting\",\"odd\",\"thanks\",\"recent\",\"comment\",\"master\",\"break\",\"lovely\",\"apart\",\"begin\",\"emotions\",\"italian\",\"party\",\"doctor\",\"la\",\"clever\",\"sequel\",\"missed\"],\"x1\":{\"__ndarray__\":\"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\",\"dtype\":\"float32\",\"order\":\"little\",\"shape\":[1000]},\"x2\":{\"__ndarray__\":\"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\",\"dtype\":\"float32\",\"order\":\"little\",\"shape\":[1000]}},\"selected\":{\"id\":\"1048\"},\"selection_policy\":{\"id\":\"1047\"}},\"id\":\"1031\",\"type\":\"ColumnDataSource\"}],\"root_ids\":[\"1003\"]},\"title\":\"Bokeh Application\",\"version\":\"2.4.1\"}};\n",
       "  const render_items = [{\"docid\":\"11d6b2fd-edf9-46d3-ab8a-9f347d6a7d6b\",\"root_ids\":[\"1003\"],\"roots\":{\"1003\":\"8342fcfe-4b62-479e-bd80-23c500af35c5\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    let attempts = 0;\n",
       "    const timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1003"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bokeh.models import ColumnDataSource, LabelSet\n",
    "from bokeh.plotting import figure, show, output_file\n",
    "from bokeh.io import output_notebook\n",
    "output_notebook()\n",
    "\n",
    "p = figure(tools=\"pan,wheel_zoom,reset,save\",\n",
    "           toolbar_location=\"above\",\n",
    "           title=\"word2vec T-SNE (eng model, top1000 words)\")\n",
    "\n",
    "source = ColumnDataSource(data=dict(x1=top_words_tsne[:,0],\n",
    "                                    x2=top_words_tsne[:,1],\n",
    "                                    names=top_words))\n",
    "\n",
    "p.scatter(x=\"x1\", y=\"x2\", size=8, source=source)\n",
    "\n",
    "labels = LabelSet(x=\"x1\", y=\"x2\", text=\"names\", y_offset=6,\n",
    "                  text_font_size=\"8pt\", text_color=\"#555555\",\n",
    "                  source=source, text_align='center')\n",
    "p.add_layout(labels)\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Szes63RX-sl"
   },
   "source": [
    "Чтобы вычислить преобразование t-SNE быстрее (и иногда еще и эффективнее), можно сперва снизить размерность исходных данных с помощью, например, SVD, и потом применять t-SNE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p0R7hvIfX-sm"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd_50 = TruncatedSVD(n_components=50)\n",
    "top_words_vec_50 = svd_50.fit_transform(top_words_vec)\n",
    "top_words_tsne2 = TSNE(n_components=2, random_state=0).fit_transform(top_words_vec_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "colab_type": "code",
    "id": "zpUJyJibX-sn",
    "outputId": "1c577f96-6f95-4bae-c327-98966e2e9a52"
   },
   "outputs": [],
   "source": [
    "output_notebook()\n",
    "\n",
    "p = figure(tools=\"pan,wheel_zoom,reset,save\",\n",
    "           toolbar_location=\"above\",\n",
    "           title=\"word2vec T-SNE (eng model, top1000 words, +SVD)\")\n",
    "\n",
    "source = ColumnDataSource(data=dict(x1=top_words_tsne2[:,0],\n",
    "                                    x2=top_words_tsne2[:,1],\n",
    "                                    names=top_words))\n",
    "\n",
    "p.scatter(x=\"x1\", y=\"x2\", size=8, source=source)\n",
    "\n",
    "labels = LabelSet(x=\"x1\", y=\"x2\", text=\"names\", y_offset=6,\n",
    "                  text_font_size=\"8pt\", text_color=\"#555555\",\n",
    "                  source=source, text_align='center')\n",
    "p.add_layout(labels)\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "2_embeddings.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
